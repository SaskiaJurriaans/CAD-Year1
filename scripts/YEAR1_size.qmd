---
title: "YEAR1 Size"
author: "Sas"
format: html
editor: visual
---

# Preparations

Load the necessary libraries

```{r}
#| label: libraries
#| output: false
#| eval: true
#| warning: false
#| message: false
#| cache: false

library(tidyverse)  #for data wrangling etc
library(rstanarm)   #for fitting models in STAN
#library(cmdstanr)   #for cmdstan --> does not work on AIMS computers
library(brms)       #for fitting models in STAN
library(standist)   #for exploring distributions
library(coda)       #for diagnostics
library(bayesplot)  #for diagnostics
library(ggmcmc)     #for MCMC diagnostics
library(DHARMa)     #for residual diagnostics
library(rstan)      #for interfacing with STAN
library(emmeans)    #for marginal means etc
library(broom)      #for tidying outputs
library(tidybayes)  #for more tidying outputs
library(HDInterval) #for HPD intervals
library(ggeffects)  #for partial plots
library(broom.mixed)#for summarising models
library(posterior)  #for posterior draws
library(ggeffects)  #for partial effects plots
library(patchwork)  #for multi-panel figures
library(bayestestR) #for ROPE
library(see)        #for some plots
library(readxl)     #to load excel documents
library(easystats)     #framework for stats, modelling and visualisation
#library(INLA)       #for approximate Bayes
library(openxlsx)    # to write excel documents
#library(INLAutils)  #for additional INLA outputs
theme_set(theme_grey()) #put the default ggplot theme back
library(lme4)
source('helperFunctions.R')
```

# Read in the data

```{r}
#| label: import data
survival <- read_excel("data/YEAR1_Survival.xlsx", 
    col_types = c("numeric", "skip", "text", 
        "skip", "skip", "numeric", "skip", 
        "text", "text", "numeric", "skip", 
        "text", "numeric", "text", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric"), na = "na")

environment <- read_excel ("data/YEAR1 Benthic Environment ReefDev.xlsx", na="na")
```

# Data tidying

**Create new column for size and remove empty rows with no size data**

```{r}
#| label: mutate survival
survival_size <- survival |>
  mutate(Size = (LinLength_mm * PerpLenght_mm * Height_mm)/1000,
         Size_log = log(Size + 1)) # Adding 1 to avoid log(0) 
```

**Separate by Reef**

Moore:

```{r}
#| label: filter moore
moore_surv <- survival_size |> filter (Reef == "Moore",
                                  Census =="t6")  

moore_env <- environment |> 
  filter (Reef == "Moore") |>
  select(-c(Reef1, Device_ID))
```

Davies:

```{r}
#| label: filter davies
davies_surv <- survival_size |> filter (Reef == "Davies",
                                   Census == "t6") 

davies_env <- environment |> 
  filter (Reef == "Davies") |>
  select(-c(Reef1, Device_ID))
```

Heron:

```{r}
heron_surv <- survival_size |> filter (Reef == "Heron",
                                  Census == "t3") 

heron_env <- environment |> 
  filter (Reef == "Heron") |>
  select(-c(Reef1, Device_ID))
```

**Merge survival and environment**

```{r}
moore <- merge(moore_env, moore_surv, by = c("Reef", "Site", "ReefDev"), all = TRUE)
davies <- merge(davies_env, davies_surv, by = c("Reef", "Site", "ReefDev"), all = TRUE)
heron <- merge(heron_env, heron_surv, by = c("Reef", "Site", "ReefDev"), all = TRUE)
```

**Free up space**

```{r}
#free up space
remove(moore_surv, moore_env)
remove(davies_surv, davies_env)
remove(heron_surv, heron_env)
remove(survival_size)
```

**Remove rows with missing values**

Moore:

```{r}
moore$SurvDev <- as.numeric(moore$SurvDev)
moore <- moore[complete.cases(moore$Size),  ]
moore <- moore |> select(-c(sedturf_t2, sedconcrete_t2))
```

Davies:

```{r}
davies$SurvDev <- as.numeric(davies$SurvDev)
davies <- davies[complete.cases(davies$Size),  ]
```

Heron:

```{r}
heron$SurvDev <- as.numeric(heron$SurvDev)
heron <- heron[complete.cases(heron$Size),  ]
heron <- heron |> select(-c(sedturf_t5, sedconcrete_t5))
```

Fill in missing values for the environmental variables (since they are the same for each device within a site). However, not PC1 and PC2 values, these are device specific (because community composition was identified around each specific device), thus missing values of PC1 and PC2 cannot be filled in and need to be removed from analyses when running regressions for habitat.

Moore:

```{r}
moore <- moore |>
  group_by(Site) |>
  mutate(
    Ub_avrg = ifelse(is.na(Ub_avrg), max(Ub_avrg, na.rm=TRUE), Ub_avrg),
    median_speed = ifelse(is.na(median_speed), max(median_speed, na.rm = TRUE), median_speed),
    percentile_10 =  ifelse(is.na(percentile_10), max(percentile_10, na.rm = TRUE), percentile_10),
    percentile_90 =  ifelse(is.na(percentile_90), max(percentile_90, na.rm = TRUE), percentile_90),
    range  =  ifelse(is.na(range), max(range, na.rm = TRUE), range),
    mean_temp = ifelse(is.na(mean_temp), max(mean_temp, na.rm = TRUE), mean_temp),
    sedturf_t5 =  ifelse(is.na(sedturf_t5), max(sedturf_t5, na.rm = TRUE), sedturf_t5),
    sedconcrete_t5 =  ifelse(is.na(sedconcrete_t5), max(sedconcrete_t5, na.rm = TRUE), sedconcrete_t5)
  ) |>
  ungroup()
```

Davies:

```{r}
davies <- davies |>
  group_by(Site) |>
  mutate(
    Ub_avrg = ifelse(is.na(Ub_avrg), max(Ub_avrg, na.rm=TRUE), Ub_avrg),
    median_speed = ifelse(is.na(median_speed), max(median_speed, na.rm = TRUE), median_speed),
    percentile_10 =  ifelse(is.na(percentile_10), max(percentile_10, na.rm = TRUE), percentile_10),
    percentile_90 =  ifelse(is.na(percentile_90), max(percentile_90, na.rm = TRUE), percentile_90),
    range  =  ifelse(is.na(range), max(range, na.rm = TRUE), range),
    mean_temp = ifelse(is.na(mean_temp), max(mean_temp, na.rm = TRUE), mean_temp),
    sedturf_t2 =  ifelse(is.na(sedturf_t2), max(sedturf_t2, na.rm = TRUE), sedturf_t2),
    sedconcrete_t2 =  ifelse(is.na(sedconcrete_t2), max(sedconcrete_t2, na.rm = TRUE), sedconcrete_t2),
    sedturf_t5 =  ifelse(is.na(sedturf_t5), max(sedturf_t5, na.rm = TRUE), sedturf_t5),
    sedconcrete_t5 =  ifelse(is.na(sedconcrete_t5), max(sedconcrete_t5, na.rm = TRUE), sedconcrete_t5)
    ) |>
  ungroup()
```

Heron:

```{r}
heron <- heron |>
  group_by(Site) |>
  mutate(
    Ub_avrg = ifelse(is.na(Ub_avrg), max(Ub_avrg, na.rm=TRUE), Ub_avrg),
    median_speed = ifelse(is.na(median_speed), max(median_speed, na.rm = TRUE), median_speed),
    percentile_10 =  ifelse(is.na(percentile_10), max(percentile_10, na.rm = TRUE), percentile_10),
    percentile_90 =  ifelse(is.na(percentile_90), max(percentile_90, na.rm = TRUE), percentile_90),
    range  =  ifelse(is.na(range), max(range, na.rm = TRUE), range),
    mean_temp = ifelse(is.na(mean_temp), max(mean_temp, na.rm = TRUE), mean_temp),
    sedturf_t2 =  ifelse(is.na(sedturf_t2), max(sedturf_t2, na.rm = TRUE), sedturf_t2),
    sedconcrete_t2 =  ifelse(is.na(sedconcrete_t2), max(sedconcrete_t2, na.rm = TRUE), sedconcrete_t2)
    ) |>
  ungroup()
```

# \-\-\-\-\-\-\-\-\-\-\-\-- GLM -------------------

# Moore

Make Site and ReefDev (id) as factors

```{r}
moore$Site <- as.factor(moore$Site)
moore$ReefDev<- as.factor(moore$ReefDev)
```

Cut median speed in bins to make it a factor

```{r}
# Decide on the number of bins
num_bins <- 10  # You can adjust this number based on your needs

# Convert median_speed to a categorical variable using cut
moore$median_speed_cat <- cut(moore$median_speed, breaks = num_bins, labels = FALSE)
moore$median_speed_cat <- as.factor(moore$median_speed_cat)

# Check the result
table(moore$median_speed_cat)
```

```{r}
moore_lmer1 <- lmer(Size ~ (1|Site), data=moore)
moore_lmer2 <- lmer(Size ~ Ub_avrg + (1|Site), data=moore)
moore_lmer3 <- lmer(Size ~ WaveEnergyLevel + (1|Site), data=moore) 
moore_lmer4 <- lmer(Size ~ median_speed + (1|Site), data=moore)
moore_lmer4cat <- lmer(Size ~ median_speed_cat + (1|Site), data=moore)
moore_lmer4log <- lmer(Size_log ~ median_speed + (1|Site), data = moore)
moore_lmer5 <- lmer(Size ~ sedturf_t5 + (1|Site), data=moore) 

summary(moore_lmer1)
summary(moore_lmer2)
summary(moore_lmer3)
summary(moore_lmer4)
summary(moore_lmer4cat)
summary(moore_lmer4log)
summary(moore_lmer5)

AIC(moore_lmer1, moore_lmer2, moore_lmer3, moore_lmer4,moore_lmer4cat, moore_lmer4log, moore_lmer5)
```

Vizualize lmer using Size as predictor

```{r}
#plot with raw data
ggplot(data=moore, aes(y = Size, x = median_speed)) + 
  geom_point()+
  geom_smooth(method="lm")

#plot with raw data and poly smoothner
ggplot(data=moore, aes(y = Size, x = median_speed)) + 
  geom_point()+
   geom_smooth(method="lm", formula = y~poly(x,3), se = FALSE)

#plot with speed as categorical data
ggplot(data=moore, aes(y = Size, x = median_speed_cat)) + 
  geom_point()

#plot wiht speed log transformed
ggplot(data=moore, aes(y = Size_log, x = median_speed)) + 
  geom_point()+
   geom_smooth(method="lm")
```

Calculate marginal means

```{r}
library(emmeans)
marginal_means<- emmeans(moore_lmer4, ~median_speed)
marginal_means_df <- as.data.frame(marginal_means)

head(marginal_means_df)
```

Calculate marginal means for the categorical variable

```{r}
marginal_means_cat <- emmeans(moore_lmer4cat, ~ median_speed_cat)
marginal_means_cat_df <- as.data.frame(marginal_means_cat)

# Inspect the marginal means dataframe
head(marginal_means_cat_df)

```

Calculate marginal means for log transformed response variable

```{r}
marginal_means_log<- emmeans(moore_lmer4log, ~median_speed)
marginal_means_log_df <- as.data.frame(marginal_means)

head(marginal_means_df)
```

Vizualize marginal means with median speed as a continuous variable

```{r}
# Plot raw data with marginal means - RAW DATA SCALE
ggplot() +
  geom_point(data = moore, aes(x = median_speed, y = Size)) +
  geom_line(data = marginal_means_df, aes(x = median_speed, y = emmean, group = 1), size = 1) +
  geom_pointrange(data = marginal_means_df, aes(x = median_speed, y = emmean, ymin = lower.CL, ymax = upper.CL), size = 1, color = "blue") +
  labs(title = "Raw Data and Marginal Means: Size vs. Median Speed - continuous ",
       x = "Median Flow velocity (m/s)",
       y = "Size") +
  theme_modern()

# Plot raw data with marginal means - LOG TRANSFORMED SCALE
ggplot() +
  geom_point(data = moore, aes(x = median_speed, y = Size_log), alpha = 0.3) +
  geom_line(data = marginal_means_log_df, aes(x = median_speed, y = emmean, group = 1), size = 1) +
  geom_pointrange(data = marginal_means_log_df, aes(x = median_speed, y = emmean, ymin = lower.CL, ymax = upper.CL), size = 1, color = "blue") +
  labs(title = "Raw Data and Marginal Means: Log(Size) vs. Median Speed (Continuous)",
       x = "Median Flow velocity (m/s)",
       y = "log(Size)") +
  theme_modern()

```

And with median speed as a categorical variable

```{r}
# Plot raw data with marginal means and confidence intervals for categorical variable
ggplot() +
  geom_point(data = moore, aes(x = median_speed_cat, y = Size), alpha = 0.3) +  # Raw data points with transparency
  geom_line(data = marginal_means_cat_df, aes(x = median_speed_cat, y = emmean, group = 1), color = "blue", size = 1) +
  geom_errorbar(data = marginal_means_cat_df, aes(x = median_speed_cat, ymin = lower.CL, ymax = upper.CL), width = 0.2, color = "blue") +
  theme_minimal() +
  labs(title = "Raw Data and Marginal Means: Size vs. Median Speed (Categorical)",
       x = "Median Speed (Categorical)",
       y = "Size") +
  theme_modern()
```

# Davies

Make Site and ReefDev (id) as factors

```{r}
davies$Site <- as.factor(davies$Site) 
davies$ReefDev<- as.factor(davies$ReefDev)
```

Cut median speed in bins to make it a factor

```{r}
# Decide on the number of bins 
num_bins <- 10

# Convert median_speed to a categorical variable using cut 
davies$median_speed_cat <- cut(davies$median_speed, breaks = num_bins, labels = FALSE) 
davies$median_speed_cat <- as.factor(davies$median_speed_cat)  

# Check the result 
table(davies$median_speed_cat)
```

```{r}
davies_lmer1 <- lmer(Size ~ (1|Site), data=davies) 
davies_lmer2 <- lmer(Size ~ Ub_avrg + (1|Site), data=davies) 
davies_lmer3 <- lmer(Size ~ WaveEnergyLevel + (1|Site), data=davies)  
davies_lmer4 <- lmer(Size ~ median_speed + (1|Site), data=davies) 
davies_lmer4cat <- lmer(Size ~ median_speed_cat + (1|Site), data=davies) 
davies_lmer4log <- lmer(Size_log ~ median_speed + (1|Site), data = davies) 
davies_lmer5 <- lmer(Size ~ sedturf_t5 + (1|Site), data=davies)  

summary(davies_lmer1) 
summary(davies_lmer2) 
summary(davies_lmer3) 
summary(davies_lmer4) 
summary(davies_lmer4cat) 
summary(davies_lmer4log) 
summary(davies_lmer5)  

AIC(davies_lmer1, davies_lmer2, davies_lmer3, davies_lmer4,davies_lmer4cat, davies_lmer4log, davies_lmer5)
```

Vizualize lmer using Size as predictor

```{r}
#plot with raw data 
ggplot(data=davies, aes(y = Size, x = median_speed)) +    
  geom_point()+   
  geom_smooth(method="lm")  

#plot with raw data and poly smoothner 
ggplot(data=davies, aes(y = Size, x = median_speed)) +    
  geom_point()+    
  geom_smooth(method="lm", formula = y~poly(x,3), se = FALSE)  

#plot with speed as categorical data 
ggplot(data=davies, aes(y = Size, x = median_speed_cat)) +    
  geom_point()  

#plot wiht speed log transformed 
ggplot(data=davies, aes(y = Size_log, x = median_speed)) +   
  geom_point()+    
  geom_smooth(method="lm")
```

Calculate marginal means

```{r}
library(emmeans) 
marginal_means<- emmeans(davies_lmer4, ~median_speed) 
marginal_means_df <- as.data.frame(marginal_means) 
head(marginal_means_df)
```

Calculate marginal means for the categorical variable

```{r}
marginal_means_cat <- emmeans(davies_lmer4cat, ~ median_speed_cat) 
marginal_means_cat_df <- as.data.frame(marginal_means_cat)  

# Inspect the marginal means dataframe 
head(marginal_means_cat_df) 
```

Calculate marginal means for log transformed response variable

```{r}
marginal_means_log<- emmeans(davies_lmer4log, ~median_speed) 
marginal_means_log_df <- as.data.frame(marginal_means)  
head(marginal_means_df)
```

Vizualize marginal means with median speed as a continuous variable

```{r}
# Plot raw data with marginal means - RAW DATA SCALE 
ggplot() +   
  geom_point(data = davies, aes(x = median_speed, y = Size)) +   
  geom_line(data = marginal_means_df, 
            aes(x = median_speed, y = emmean, group = 1), 
            size = 1) +   
  geom_pointrange(data = marginal_means_df, 
                  aes(x = median_speed, y = emmean, ymin = lower.CL, ymax = upper.CL), 
                  size = 1, 
                  color = "blue") +   
  labs(title = "Raw Data and Marginal Means: Size vs. Median Speed - continuous ",        
       x = "Median Flow velocity (m/s)",        
       y = "Size") +   
  theme_modern()  

# Plot raw data with marginal means - LOG TRANSFORMED SCALE 
ggplot() +   
  geom_point(data = davies, 
             aes(x = median_speed, y = Size_log), 
             alpha = 0.3) +   
  geom_line(data = marginal_means_log_df, 
            aes(x = median_speed, y = emmean, group = 1), 
            size = 1) +   
  geom_pointrange(data = marginal_means_log_df, 
                  aes(x = median_speed, y = emmean, ymin = lower.CL, ymax = upper.CL), 
                  size = 1, 
                  color = "blue") +  
  labs(title = "Raw Data and Marginal Means: Log(Size) vs. Median Speed (Continuous)",        
       x = "Median Flow velocity (m/s)",       
       y = "log(Size)") +  
  theme_modern() 
```

And with median speed as a categorical variable

```{r}
# Plot raw data with marginal means and confidence intervals for categorical variable 
ggplot() +   
  geom_point(data = davies, aes(x = median_speed_cat, y = Size), alpha = 0.3) +  # Raw data points with transparency   
  geom_line(data = marginal_means_cat_df, aes(x = median_speed_cat, y = emmean, group = 1), color = "blue", size = 1) + 
  geom_errorbar(data = marginal_means_cat_df, aes(x = median_speed_cat, ymin = lower.CL, ymax = upper.CL), width = 0.2, color = "blue") +   
  theme_minimal() +   
  labs(title = "Raw Data and Marginal Means: Size vs. Median Speed (Categorical)",        
       x = "Median Speed (Categorical)",        
       y = "Size") +   
  theme_modern()
```

# Heron

Make Site and ReefDev (id) as factors

```{r}
heron$Site <- as.factor(heron$Site) 
heron$ReefDev<- as.factor(heron$ReefDev)
```

Cut median speed in bins to make it a factor

```{r}
# Decide on the number of bins 
num_bins <- 10  # You can adjust this number based on your needs  

# Convert median_speed to a categorical variable using cut 
heron$median_speed_cat <- cut(heron$median_speed, breaks = num_bins, labels = FALSE) 
heron$median_speed_cat <- as.factor(heron$median_speed_cat)  

# Check the result 
table(heron$median_speed_cat)
```

```{r}
heron_lmer1 <- lmer(Size ~ (1|Site), data=heron) 
heron_lmer2 <- lmer(Size ~ Ub_avrg + (1|Site), data=heron) 
heron_lmer3 <- lmer(Size ~ WaveEnergyLevel + (1|Site), data=heron)  
heron_lmer4 <- lmer(Size ~ median_speed + (1|Site), data=heron) 
heron_lmer4cat <- lmer(Size ~ median_speed_cat + (1|Site), data=heron) 
heron_lmer4log <- lmer(Size_log ~ median_speed + (1|Site), data = heron) 
heron_lmer5 <- lmer(Size ~ sedturf_t2 + (1|Site), data=heron)
heron_lmer6 <- lmer(Size ~ sedconcrete_t2 + (1|Site), data=heron)   

summary(heron_lmer1) 
summary(heron_lmer2) 
summary(heron_lmer3) 
summary(heron_lmer4) 
summary(heron_lmer4cat) 
summary(heron_lmer4log) 
summary(heron_lmer5)
summary(heron_lmer6) 

AIC(heron_lmer1, heron_lmer2, heron_lmer3, heron_lmer4,heron_lmer4cat, heron_lmer4log, heron_lmer5, heron_lmer6)
```

Vizualize lmer using Size as predictor

```{r}
#plot with raw data 
ggplot(data=heron, aes(y = Size, x = median_speed)) +    
  geom_point()+   
  geom_smooth(method="lm")  

#plot with raw data and poly smoothner 
ggplot(data=heron, aes(y = Size, x = median_speed)) +    
  geom_point()+    
  geom_smooth(method="lm", formula = y~poly(x,3), se = FALSE)  

#plot with speed as categorical data 
ggplot(data=heron, aes(y = Size, x = median_speed_cat)) +    
  geom_point()  

#plot wiht speed log transformed 
ggplot(data=heron, aes(y = Size_log, x = median_speed)) +    
  geom_point()+    
  geom_smooth(method="lm")
```

Calculate marginal means

```{r}
library(emmeans) 
marginal_means<- emmeans(heron_lmer4, ~median_speed) 
marginal_means_df <- as.data.frame(marginal_means)  
head(marginal_means_df)
```

Calculate marginal means for the categorical variable

```{r}
marginal_means_cat <- emmeans(heron_lmer4cat, ~ median_speed_cat) 
marginal_means_cat_df <- as.data.frame(marginal_means_cat)  

# Inspect the marginal means dataframe 
head(marginal_means_cat_df) 
```

Calculate marginal means for log transformed response variable

```{r}
marginal_means_log<- emmeans(heron_lmer4log, ~median_speed) 
marginal_means_log_df <- as.data.frame(marginal_means)  
head(marginal_means_df)
```

Vizualize marginal means with median speed as a continuous variable

```{r}
# Plot raw data with marginal means - RAW DATA SCALE 
ggplot() +   geom_point(data = heron, aes(x = median_speed, y = Size)) +  
  geom_line(data = marginal_means_df, aes(x = median_speed, y = emmean, group = 1), size = 1) +   
  geom_pointrange(data = marginal_means_df, aes(x = median_speed, y = emmean, ymin = lower.CL, ymax = upper.CL), size = 1, color = "blue") +  
  labs(title = "Raw Data and Marginal Means: Size vs. Median Speed - continuous ",        
       x = "Median Flow velocity (m/s)",        
       y = "Size") +   
  theme_modern()  

# Plot raw data with marginal means - LOG TRANSFORMED SCALE 
ggplot() +   
  geom_point(data = heron, 
             aes(x = median_speed, y = Size_log), 
             alpha = 0.3) +   
  geom_line(data = marginal_means_log_df, 
            aes(x = median_speed, y = emmean, group = 1), 
            size = 1) +  
  geom_pointrange(data = marginal_means_log_df, 
                  aes(x = median_speed, y = emmean, ymin = lower.CL, ymax = upper.CL), 
                  size = 1, 
                  color = "blue") +   
  labs(title = "Raw Data and Marginal Means: Log(Size) vs. Median Speed (Continuous)",        
       x = "Median Flow velocity (m/s)",        
       y = "log(Size)") +   
  theme_modern() 
```

And with median speed as a categorical variable

```{r}
# Plot raw data with marginal means and confidence intervals for categorical variable 
ggplot() +   
  geom_point(data = heron, aes(x = median_speed_cat, y = Size), alpha = 0.3) +  # Raw data points with transparency   
  geom_line(data = marginal_means_cat_df, aes(x = median_speed_cat, y = emmean, group = 1), color = "blue", size = 1) +   
  geom_errorbar(data = marginal_means_cat_df, aes(x = median_speed_cat, ymin = lower.CL, ymax = upper.CL), width = 0.2, color = "blue") +   
  theme_minimal() +   
  labs(title = "Raw Data and Marginal Means: Size vs. Median Speed (Categorical)",        
       x = "Median Speed (Categorical)",        
       y = "Size") +   
  theme_modern()
```

# \-\-\-\-\-\-\-\-\-\-\-\-- Bayesian-----------------

# Moore

##### brm1 - wave

```{r}
moore_size_wave <-  bf(Size_log ~ WaveEnergyLevel + (1|Site), family = gaussian())

priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept
  prior(normal(0,5), class = "b") +                   # for fixed effects - WaveEnergyLevel
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site

moore_brm1_size <- brm(moore_size_wave,
                 data=moore,
                 prior = priors,
                 sample_prior = 'yes',
                 iter = 5000,
                 warmup = 1000,
                 chains = 3, cores = 3,
                 thin = 5,
                 refresh = 0,
                 control = list(adapt_delta = 0.99),
                backend = "rstan")

# To save the model use >> 
#save(moore_brm1_size, file = "scripts/models/moore/size/moore_brm1_size.RData")
```

Model diagnostics

```{r}
moore_brm1_size |> pp_check(type = 'dens_overlay', ndraws = 100)
moore_brm1_size |> pp_check (type = "error_scatter_avg")
moore_brm1_size  |> pp_check(group = 'Site', type = 'violin_grouped')

moore.resids1 <- make_brms_dharma_res(moore_brm1_size, integerResponse = FALSE)
testUniformity(moore.resids1)
plotResiduals(moore.resids1)
testDispersion(moore.resids1)
```

##### brm2 - Ub_avrg

```{r}
moore_size_Ub <-  bf(Size_log ~ Ub_avrg + (1|Site), family = gaussian())

priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept
  prior(normal(0,5), class = "b") +                   # for fixed effects - Ub
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site

moore_brm2_size <- brm(moore_size_Ub,
                 data=moore,
                 prior = priors,
                 sample_prior = 'yes',
                 iter = 5000,
                 warmup = 1000,
                 chains = 3, cores = 3,
                 thin = 5,
                 refresh = 0,
                 control = list(adapt_delta = 0.99),
                backend = "rstan")

# To save the model use >> 
#save(moore_brm2_size, file = "scripts/models/moore/size/moore_brm2_size.RData")
```

Model diagnostics

```{r}
moore_brm2_size |> pp_check(type = 'dens_overlay', ndraws = 100)
moore_brm2_size |> pp_check (type = "error_scatter_avg")
moore_brm2_size  |> pp_check(group = 'Site', type = 'violin_grouped')

moore.resids2 <- make_brms_dharma_res(moore_brm2_size, integerResponse = FALSE)
testUniformity(moore.resids2)
plotResiduals(moore.resids2)
testDispersion(moore.resids2)
```

##### brm3 - median_speed

```{r}
moore_size_speed <-  bf(Size_log ~ median_speed + (1|Site), family = gaussian())

priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept
  prior(normal(0,5), class = "b") +                   # for fixed effects - speed
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site

moore_brm3_size <- brm(moore_size_speed,
                 data=moore,
                 prior = priors,
                 sample_prior = 'yes',
                 iter = 5000,
                 warmup = 1000,
                 chains = 3, cores = 3,
                 thin = 5,
                 refresh = 0,
                 control = list(adapt_delta = 0.99),
                backend = "rstan")

# To save the model use >> 
#save(moore_brm3_size, file = "scripts/models/moore/size/moore_brm3_size.RData")

```

Model diagnostics

```{r}
moore_brm3_size |> pp_check(type = 'dens_overlay', ndraws = 100)
moore_brm3_size |> pp_check (type = "error_scatter_avg")
moore_brm3_size  |> pp_check(group = 'Site', type = 'violin_grouped')

moore.resids3 <- make_brms_dharma_res(moore_brm3_size, integerResponse = FALSE)
testUniformity(moore.resids3)
plotResiduals(moore.resids3)
testDispersion(moore.resids3)
```

##### brm4- sedturf_t5

```{r}
moore_size_turf <-  bf(Size_log ~ sedturf_t5 + (1|Site), family = gaussian())

priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept
  prior(normal(0,5), class = "b") +                   # for fixed effects - speed
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site

moore_brm4_size <- brm(moore_size_turf,
                 data=moore,
                 prior = priors,
                 sample_prior = 'yes',
                 iter = 5000,
                 warmup = 1000,
                 chains = 3, cores = 3,
                 thin = 5,
                 refresh = 0,
                 control = list(adapt_delta = 0.99),
                backend = "rstan")

# To save the model use >> 
#save(moore_brm4_size, file = "scripts/models/moore/size/moore_brm4_size.RData")

```

Model diagnostics

```{r}
moore_brm4_size |> pp_check(type = 'dens_overlay', ndraws = 100)
moore_brm4_size |> pp_check (type = "error_scatter_avg")
moore_brm4_size  |> pp_check(group = 'Site', type = 'violin_grouped')

moore.resids4 <- make_brms_dharma_res(moore_brm4_size, integerResponse = FALSE)
testUniformity(moore.resids4)
plotResiduals(moore.resids4)
testDispersion(moore.resids4)
```

##### brm5 - sedconcrete_t5

```{r}
moore_size_concrete <-  bf(Size_log ~ sedconcrete_t5 + (1|Site), family = gaussian())

priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept
  prior(normal(0,5), class = "b") +                   # for fixed effects - speed
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site

moore_brm5_size <- brm(moore_size_concrete,
                 data=moore,
                 prior = priors,
                 sample_prior = 'yes',
                 iter = 5000,
                 warmup = 1000,
                 chains = 3, cores = 3,
                 thin = 5,
                 refresh = 0,
                 control = list(adapt_delta = 0.99),
                backend = "rstan")

# To save the model use >> 
#save(moore_brm5_size, file = "scripts/models/moore/size/moore_brm5_size.RData")
```

Model diagnostics

```{r}
moore_brm5_size |> pp_check(type = 'dens_overlay', ndraws = 100)
moore_brm5_size |> pp_check (type = "error_scatter_avg")
moore_brm5_size  |> pp_check(group = 'Site', type = 'violin_grouped')

moore.resids5 <- make_brms_dharma_res(moore_brm5_size, integerResponse = FALSE)
testUniformity(moore.resids5)
plotResiduals(moore.resids5)
testDispersion(moore.resids5)
```

##### brm6 - habitat

```{r}
moore_size_habitat <-  bf(Size_log ~ PC1 + PC2 + (1|Site), family = gaussian())

priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept
  prior(normal(0,5), class = "b") +                   # for fixed effects - speed
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site

moore_brm6_size <- brm(moore_size_habitat,
                 data=moore,
                 prior = priors,
                 sample_prior = 'yes',
                 iter = 5000,
                 warmup = 1000,
                 chains = 3, cores = 3,
                 thin = 5,
                 refresh = 0,
                 control = list(adapt_delta = 0.99),
                backend = "rstan")

# To save the model use >> 
#save(moore_brm6_size, file = "scripts/models/moore/size/moore_brm6_size.RData")
```

Model diagnostics

```{r}
moore_brm6_size |> pp_check(type = 'dens_overlay', ndraws = 100)
moore_brm6_size |> pp_check (type = "error_scatter_avg")
moore_brm6_size  |> pp_check(group = 'Site', type = 'violin_grouped')

moore.resids6 <- make_brms_dharma_res(moore_brm6_size, integerResponse = FALSE)
testUniformity(moore.resids6)
plotResiduals(moore.resids6)
testDispersion(moore.resids6)
```

INTERPRETATION:

**dens-overlay:** dark blue line represent the density of the observed data, the light blue lines represent the densities of simulated data from the posterior predictive distribution of the model (thus "replicated data"). Reasonable fit, the peak is around zero for the observed and replicated data, also the observed density falls generally within the rand of the replicated densities, suggesting that the model is performing well in capturing the overall distribution of the observed data.

**error-scatter:** x-acis shows the average difference between the observed data and replicated (simulated) data. The y-axis represents the observed data. An ideal fit would be when the points cluster around the diagonal line where y is equal to the average yrep. In this case, the scatter points show a positive trend, indicating that higher observed values (y) correspond to higher average differences (y - yrep). The points are reasonably well aligned with the diagonal line, suggesting that the model's predictions are generally consistent with the observed data. However, there are some deviations at the higher observed values, suggesting that the model might not be fully capturing the variability in these observations.

**violin-plot:** the black line represent the distribution of the observed data within each site. They light blue fill represents the distribution of the simulated data within each site. Wider sections indicate higher density. A good fit would be when the black outlines are well alligned with the light blue fill, indicating that the model's simulated data closely matches the observed data. In this case, the observed data at most sites are well aligned with the predicted data, suggesting that the model captures the general distribution within these sites. However, some sites have a little deviation, for instance site M4A has a wider spread in the observed data compared to the simulated data.

**QQ-residuals:** the red line represents the expected theoretical quantiles if the residuals were perfectly uniform. However, the observed quantiles deviate from the red line, which is consistent with the Kolmogorov-Smirnov test (p-value = 0.02334), indicating significant deviation from uniformity.

**Residuals vs. Predicted**: The black points should ideally scatter around the horizontal line at 0.5 if the model fits well. The black line (trend) should be flat if there are no systematic deviations. The plot shows some deviations from the horizontal line, suggesting possible non-uniformity or other issues. The red curve indicates the detected quantile deviations, suggesting some systematic deviations in certain quantiles of the residuals. However, the combined adjusted quantile test is not significant, suggesting that while there are some deviations, they are not strong enough to be statistically significant.

**Dispersion test:** Evaluates whether the residual variance (dispersion) in the model is consistent with the expected variance under the model's assumptions. The histogram shows the distribution of the simulated residual standard deviations. The red line (fitted model) lies well within the bulk of the simulated values, suggesting that the model does not exhibit significant dispersion issues. Also, the output shows a dispersion of 0.87029. A dispersion parameter close to 1 indicates that the observed residual variance is consistent with the model's expectations. In this case, the dispersion parameter is 0.87029, which is close to 1. Also, the p-value is 0.69, suggesting that there is no significant overdispersion or underdispersion.

### Load models

```{r}
load(file = "scripts/models/moore/size/moore_brm1_size.RData")
load(file = "scripts/models/moore/size/moore_brm2_size.RData")
load(file = "scripts/models/moore/size/moore_brm3_size.RData")
load(file = "scripts/models/moore/size/moore_brm4_size.RData")
load(file = "scripts/models/moore/size/moore_brm5_size.RData")
load(file = "scripts/models/moore/size/moore_brm6_size.RData")
```

### Loo compare

```{r}
#Using loo compare, lower value is better
l_wave <- moore_brm1_size |> loo()
l_Ub <- moore_brm2_size |> loo()
l_speed <- moore_brm3_size |> loo()
l_turf <- moore_brm4_size|> loo()
l_concrete <- moore_brm5_size|> loo()
l_habitat <- moore_brm6_size|> loo()

looic(moore_brm1_size)      #  LOOIC: 332.38 [16.84]
looic(moore_brm2_size)      #  LOOIC: 331.93 [16.93]
looic(moore_brm3_size)      #  LOOIC: 332.46 [16.88]
looic(moore_brm4_size)      #  LOOIC: 332.39 [16.73]
looic(moore_brm5_size)      #  LOOIC: 332.68 [16.80]
looic(moore_brm6_size)      #  LOOIC: 309.34 [16.93]

l_speed
l_Ub
l_wave
l_turf
l_concrete
l_habitat
```

**NOTES ON THIS:**

**LOOIC (Leave-One-Out Information Criterion)**: A measure of the model's predictive accuracy. Lower LOOIC values indicate a better model.

**ELPD (Expected Log Predictive Density)**: A measure of the model's predictive performance. Higher ELPD values indicate a better model.

**Standard Error (SE)**: The standard error of the LOOIC or ELPD estimates.

**\*\* Best Model**: `moore_brm6_size` ([l_habitat]{.underline}) has the highest ELPD(-154.67) and the lowest LOOIC (309.34), indicating the best predictive performance among the models compared.

**\*\* Worst Model**: `moore_brm5_size` ([l_concrete]{.underline}) has the lowest ELPD and the highest LOOIC, indicating the worst predictive performance among the models compared.

### Summary

```{r}
summary(moore_brm1_size)
summary(moore_brm2_size)
summary(moore_brm3_size)
summary(moore_brm4_size)
summary(moore_brm5_size)
summary(moore_brm6_size)
```

**NOTES ON THIS:** None of the predictors (PC1, PC2, WaveEnergyLevel, Ub_avrg, median_speed, sedturf_t5, sedconcrete_t5) have credible intervals that exclude zero, suggesting that these predictors are not significantly associated with `Size_log`. According to the LOOIC and ELPD values above, moore_brm6_size (with PC1 and PC2) seems to be the best model.

All models have good convergence diagnostics (Rhat = 1.00) and sufficient effect sample sizes (Bulk_ESS and Tail_ESS) indicating reliable parameter estimates.

# \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--

# Davies

##### brm1 - wave

```{r}
davies_size_wave <-  bf(Size_log ~ WaveEnergyLevel + (1|Site), family = gaussian())  

priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept   
  prior(normal(0,5), class = "b") +                   # for fixed effects - WaveEnergyLevel   
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site  

davies_brm1_size <- brm(davies_size_wave,                  
                       data=davies,                  
                       prior = priors,                  
                       sample_prior = 'yes',                  
                       iter = 5000,                  
                       warmup = 1000,                  
                       chains = 3, cores = 3,                  
                       thin = 5,                  
                       refresh = 0,                  
                       control = list(adapt_delta = 0.99),                 
                       backend = "rstan")  

# To save the model use >>  
#save(davies_brm1_size, file = "scripts/models/davies/size/davies_brm1_size.RData")
```

Model diagnostics

```{r}
davies_brm1_size |> pp_check(type = 'dens_overlay', ndraws = 100) 
davies_brm1_size |> pp_check (type = "error_scatter_avg") 
davies_brm1_size  |> pp_check(group = 'Site', type = 'violin_grouped') 

davies.resids1 <- make_brms_dharma_res(davies_brm1_size, integerResponse = FALSE) 
testUniformity(davies.resids1) 
plotResiduals(davies.resids1) 
testDispersion(davies.resids1)
```

##### brm2 - Ub_avrg

```{r}
davies_size_Ub <-  bf(Size_log ~ Ub_avrg + (1|Site), family = gaussian())  
priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept   
  prior(normal(0,5), class = "b") +                   # for fixed effects - Ub   
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site  

davies_brm2_size <- brm(davies_size_Ub,                  
                       data=davies,                  
                       prior = priors,                  
                       sample_prior = 'yes',               
                       iter = 5000,                  
                       warmup = 1000,                
                       chains = 3, 
                       cores = 3,     
                       thin = 5,   
                       refresh = 0,              
                       control = list(adapt_delta = 0.99),  
                       backend = "rstan")  

# To save the model use >>  
#save(davies_brm2_size, file = "scripts/models/davies/size/davies_brm2_size.RData")
```

Model diagnostics

```{r}
davies_brm2_size |> pp_check(type = 'dens_overlay', ndraws = 100) 
davies_brm2_size |> pp_check (type = "error_scatter_avg") 
davies_brm2_size  |> pp_check(group = 'Site', type = 'violin_grouped')  

davies.resids2 <- make_brms_dharma_res(davies_brm2_size, integerResponse = FALSE) 
testUniformity(davies.resids2) 
plotResiduals(davies.resids2) 
testDispersion(davies.resids2)
```

##### brm3 - median_speed

```{r}
davies_size_speed <-  bf(Size_log ~ median_speed + (1|Site), family = gaussian())  
priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept   
  prior(normal(0,5), class = "b") +                   # for fixed effects - speed   
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site  

davies_brm3_size <- brm(davies_size_speed,               
                       data=davies,              
                       prior = priors,    
                       sample_prior = 'yes',           
                       iter = 5000,     
                       warmup = 1000,         
                       chains = 3, 
                       cores = 3,       
                       thin = 5,                 
                       refresh = 0,          
                       control = list(adapt_delta = 0.99),     
                       backend = "rstan")  

# To save the model use >>  
#save(davies_brm3_size, file = "scripts/models/davies/size/davies_brm3_size.RData") 
```

Model diagnostics

```{r}
davies_brm3_size |> pp_check(type = 'dens_overlay', ndraws = 100)
davies_brm3_size |> pp_check (type = "error_scatter_avg")
davies_brm3_size  |> pp_check(group = 'Site', type = 'violin_grouped') 

davies.resids3 <- make_brms_dharma_res(davies_brm3_size, integerResponse = FALSE)
testUniformity(davies.resids3) 
plotResiduals(davies.resids3) 
testDispersion(davies.resids3)
```

##### brm4- sedturf_t2

```{r}
davies_size_turf2 <-  bf(Size_log ~ sedturf_t2 + (1|Site), family = gaussian()) 

priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept  
  prior(normal(0,5), class = "b") +                   # for fixed effects - speed 
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site 

davies_brm4_size <- brm(davies_size_turf2,                
                       data=davies,           
                       prior = priors,             
                       sample_prior = 'yes',             
                       iter = 5000,         
                       warmup = 1000,    
                       chains = 3, 
                       cores = 3,    
                       thin = 5,             
                       refresh = 0,                 
                       control = list(adapt_delta = 0.99),      
                       backend = "rstan") 

# To save the model use >>  
#save(davies_brm4_size, file = "scripts/models/davies/size/davies_brm4_size.RData") 
```

Model diagnostics

```{r}
davies_brm4_size |> pp_check(type = 'dens_overlay', ndraws = 100) 
davies_brm4_size |> pp_check (type = "error_scatter_avg") 
davies_brm4_size  |> pp_check(group = 'Site', type = 'violin_grouped') 

davies.resids4 <- make_brms_dharma_res(davies_brm4_size, integerResponse = FALSE) 
testUniformity(davies.resids4) 
plotResiduals(davies.resids4) 
testDispersion(davies.resids4)
```

##### brm5 - sedconcrete_t2

```{r}
davies_size_concrete2 <-  bf(Size_log ~ sedconcrete_t2 + (1|Site), family = gaussian()) 
priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept  
  prior(normal(0,5), class = "b") +                   # for fixed effects - speed   
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site  

davies_brm5_size <- brm(davies_size_concrete2,            
                       data=davies,              
                       prior = priors,               
                       sample_prior = 'yes',              
                       iter = 5000,            
                       warmup = 1000,     
                       chains = 3, 
                       cores = 3,       
                       thin = 5,            
                       refresh = 0,               
                       control = list(adapt_delta = 0.99), 
                       backend = "rstan")  

# To save the model use >>  
#save(davies_brm5_size, file = "scripts/models/davies/size/davies_brm5_size.RData")
```

Model diagnostics

```{r}
davies_brm5_size |> pp_check(type = 'dens_overlay', ndraws = 100) 
davies_brm5_size |> pp_check (type = "error_scatter_avg") 
davies_brm5_size  |> pp_check(group = 'Site', type = 'violin_grouped') 

davies.resids5 <- make_brms_dharma_res(davies_brm5_size, integerResponse = FALSE) 
testUniformity(davies.resids5) 
plotResiduals(davies.resids5)
testDispersion(davies.resids5)
```

##### brm6 - sedturf_t5

```{r}
davies_size_turf5 <-  bf(Size_log ~ sedturf_t5 + (1|Site), family = gaussian()) 

priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept  
  prior(normal(0,5), class = "b") +                   # for fixed effects - speed 
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site 

davies_brm6_size <- brm(davies_size_turf5,                
                       data=davies,           
                       prior = priors,             
                       sample_prior = 'yes',             
                       iter = 5000,         
                       warmup = 1000,    
                       chains = 3, 
                       cores = 3,    
                       thin = 5,             
                       refresh = 0,                 
                       control = list(adapt_delta = 0.99),      
                       backend = "rstan") 

# To save the model use >>  
#save(davies_brm6_size, file = "scripts/models/davies/size/davies_brm6_size.RData") 
```

Model diagnostics

```{r}
davies_brm6_size |> pp_check(type = 'dens_overlay', ndraws = 100)
davies_brm6_size |> pp_check (type = "error_scatter_avg") 
davies_brm6_size  |> pp_check(group = 'Site', type = 'violin_grouped') 

davies.resids6 <- make_brms_dharma_res(davies_brm6_size, integerResponse = FALSE) 
testUniformity(davies.resids6) 
plotResiduals(davies.resids6)
testDispersion(davies.resids6)
```

##### brm7 - sedconcrete_t5

```{r}
davies_size_concrete5 <-  bf(Size_log ~ sedconcrete_t5 + (1|Site), family = gaussian()) 
priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept  
  prior(normal(0,5), class = "b") +                   # for fixed effects - speed   
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site  

davies_brm7_size <- brm(davies_size_concrete5,            
                       data=davies,              
                       prior = priors,               
                       sample_prior = 'yes',              
                       iter = 5000,            
                       warmup = 1000,     
                       chains = 3, 
                       cores = 3,       
                       thin = 5,            
                       refresh = 0,               
                       control = list(adapt_delta = 0.99), 
                       backend = "rstan")  

# To save the model use >>  
#save(davies_brm7_size, file = "scripts/models/davies/size/davies_brm7_size.RData")
```

Model diagnostics

```{r}
davies_brm7_size |> pp_check(type = 'dens_overlay', ndraws = 100)
davies_brm7_size |> pp_check (type = "error_scatter_avg") 
davies_brm7_size  |> pp_check(group = 'Site', type = 'violin_grouped') 

davies.resids7 <- make_brms_dharma_res(davies_brm7_size, integerResponse = FALSE) 
testUniformity(davies.resids7) 
plotResiduals(davies.resids7)
testDispersion(davies.resids7)
```

##### brm8 - habitat

```{r}
davies_size_habitat <-  bf(Size_log ~ PC1 + PC2 + (1|Site), family = gaussian())  
priors <- prior(normal(0, 5), class = "Intercept") +  # for intercept 
  prior(normal(0,5), class = "b") +                   # for fixed effects - speed   
  prior(cauchy(0,2), class = 'sd')                    # for random effects - Site  

davies_brm8_size <- brm(davies_size_habitat, 
                       data=davies,             
                       prior = priors,  
                       sample_prior = 'yes',        
                       iter = 5000,            
                       warmup = 1000,          
                       chains = 3, 
                       cores = 3,  
                       thin = 5,           
                       refresh = 0,         
                       control = list(adapt_delta = 0.99),      
                       backend = "rstan")  

# To save the model use >> 
#save(davies_brm8_size, file = "scripts/models/davies/size/davies_brm8_size.RData")
```

Model diagnostics

```{r}
davies_brm8_size |> pp_check(type = 'dens_overlay', ndraws = 100)
davies_brm8_size |> pp_check (type = "error_scatter_avg") 
davies_brm8_size  |> pp_check(group = 'Site', type = 'violin_grouped') 

davies.resids8 <- make_brms_dharma_res(davies_brm8_size, integerResponse = FALSE) 
testUniformity(davies.resids8) 
plotResiduals(davies.resids8)
testDispersion(davies.resids8)
```

INTERPRETATION:

**dens-overlay:** dark blue line represent the density of the observed data, the light blue lines represent the densities of simulated data from the posterior predictive distribution of the model (thus "replicated data"). Reasonable fit, the peak is around zero for the observed and replicated data, also the observed density falls generally within the rand of the replicated densities, suggesting that the model is performing well in capturing the overall distribution of the observed data.

**error-scatter:** x-acis shows the average difference between the observed data and replicated (simulated) data. The y-axis represents the observed data. An ideal fit would be when the points cluster around the diagonal line where y is equal to the average yrep. In this case, the scatter points show a positive trend, indicating that higher observed values (y) correspond to higher average differences (y - yrep). The points are reasonably well aligned with the diagonal line, suggesting that the model's predictions are generally consistent with the observed data. However, there are some deviations at the higher observed values, suggesting that the model might not be fully capturing the variability in these observations.

**violin-plot:** the black line represent the distribution of the observed data within each site. They light blue fill represents the distribution of the simulated data within each site. Wider sections indicate higher density. A good fit would be when the black outlines are well alligned with the light blue fill, indicating that the model's simulated data closely matches the observed data. In this case, the observed data at most sites are well aligned with the predicted data, suggesting that the model captures the general distribution within these sites. However, some sites have a little deviation, for instance site M4A has a wider spread in the observed data compared to the simulated data.

**QQ-residuals:** the red line represents the expected theoretical quantiles if the residuals were perfectly uniform. However, the observed quantiles deviate from the red line, which is consistent with the Kolmogorov-Smirnov test, indicating significant deviation from uniformity.

**Residuals vs. Predicted**: The black points should ideally scatter around the horizontal line at 0.5 if the model fits well. The black line (trend) should be flat if there are no systematic deviations. The plot shows some deviations from the horizontal line, suggesting possible non-uniformity or other issues. The red curve indicates the detected quantile deviations, suggesting some systematic deviations in certain quantiles of the residuals. However, the combined adjusted quantile test is not significant, suggesting that while there are some deviations, they are not strong enough to be statistically significant.

**Dispersion test:** Evaluates whether the residual variance (dispersion) in the model is consistent with the expected variance under the model's assumptions. The histogram shows the distribution of the simulated residual standard deviations. The red line (fitted model) lies well within the bulk of the simulated values, suggesting that the model does not exhibit significant dispersion issues. Also, the output shows a dispersion of 0.87029. A dispersion parameter close to 1 indicates that the observed residual variance is consistent with the model's expectations. In this case, the dispersion parameter is 0.87029, which is close to 1. Also, the p-value is 0.69, suggesting that there is no significant overdispersion or underdispersion.

#### Load models

```{r}
load(file = "scripts/models/davies/size/davies_brm1_size.RData") 
load(file = "scripts/models/davies/size/davies_brm2_size.RData")
load(file = "scripts/models/davies/size/davies_brm3_size.RData")
load(file = "scripts/models/davies/size/davies_brm4_size.RData") 
load(file = "scripts/models/davies/size/davies_brm5_size.RData")
load(file = "scripts/models/davies/size/davies_brm6_size.RData")
```

#### Loo compare

```{r}
#Using loo compare, lower value is better 
l_wave <- davies_brm1_size |> loo() 
l_Ub <- davies_brm2_size |> loo() 
l_speed <- davies_brm3_size |> loo() 
l_turf2 <- davies_brm4_size|> loo() 
l_concrete2 <- davies_brm5_size|> loo()
l_turf5 <- davies_brm6_size|> loo() 
l_concrete5 <- davies_brm7_size|> loo()
l_habitat <- davies_brm8_size|> loo() 

looic(davies_brm1_size)      #  LOOIC: 133.64 [10.01] 
looic(davies_brm2_size)      #  LOOIC: 133.35 [9.87]
looic(davies_brm3_size)      #  LOOIC: 133.41 [10.20]
looic(davies_brm4_size)      #  LOOIC: 133.06 [10.48]
looic(davies_brm5_size)      #  LOOIC: 131.72 [10.51]
looic(davies_brm6_size)      #  LOOIC: 133.71 [10.12]
looic(davies_brm7_size)      #  LOOIC: 133.31 [10.11] 
looic(davies_brm8_size)      #  LOOIC: 134.95 [9.71]

l_speed 
l_Ub
l_wave
l_turf2 
l_concrete2
l_turf5 
l_concrete5 
l_habitat
```

**NOTES ON THIS:**

**LOOIC (Leave-One-Out Information Criterion)**: A measure of the model's predictive accuracy. Lower LOOIC values indicate a better model.

**ELPD (Expected Log Predictive Density)**: A measure of the model's predictive performance. Higher ELPD values indicate a better model.

**Standard Error (SE)**: The standard error of the LOOIC or ELPD estimates.

**\*\* Best Model**: `davies_brm5_size` ([l_concrete_t2]{.underline}) has the highest ELPD(-65.86) and the lowest LOOIC (131.72), indicating the best predictive performance among the models compared. However, davies_brm4_size (l_turf_t2) is in a close second place.

**\*\* Worst Model**: `davies_brm8_size` ([l_habitat]{.underline}) has the lowest ELPD and the highest LOOIC, indicating the worst predictive performance among the models compared.

#### Summary

```{r}
summary(davies_brm1_size)
summary(davies_brm2_size)
summary(davies_brm3_size)
summary(davies_brm4_size)
summary(davies_brm5_size)
summary(davies_brm6_size)
summary(davies_brm7_size)
summary(davies_brm8_size)
```

**NOTES ON THIS:**

-   **Random Effects**: The standard deviation for the intercepts across all models suggests some variability among the sites.

-   **Fixed Effects**: None of the predictors (WaveEnergyLevel, Ub_avrg, median_speed, sedturf_t2, sedconcrete_t2, sedturf_t5) are statistically significant in predicting `Size_log`.

-   **Residuals**: The residual standard deviation (sigma) is consistent across models, indicating a similar level of unexplained variance.

Based on the LOOIC and ELPD values, **davies_brm5_size** appears to be the best-fitting model among those evaluated. However, since none of the fixed effects are significant, it suggests that these predictors may not be strong influencers of `Size_log` in this dataset.

All models have good convergence diagnostics (Rhat = 1.00) and sufficient effect sample sizes (Bulk_ESS and Tail_ESS) indicating reliable parameter estimates.
