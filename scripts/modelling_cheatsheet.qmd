---
title: Modelling Cheatsheet 
author: "Murray Logan"
date: today
date-format: "DD/MM/YYYY"
format: 
  html:
    css: ../resources/ws_style.css
    toc: true
    toc-float: true
    embed-resources: true
    number-sections: true
    theme: spacelab
    highlight-style: zenburn
    number-depth: 3
    code-fold: false
    code-tools: true
    code-summary: "Show the code"
crossref:
  fig-title: '**Figure**'
  fig-labels: arabic
  tbl-title: '**Table**'
  tbl-labels: arabic
engine: knitr
bibliography: ../resources/references.bib
output_dir: "docs"
documentclass: article
fontsize: 12pt
mainfont: Arial
mathfont: LiberationMono
monofont: DejaVu Sans Mono
classoption: a4paper
editor: 
  markdown: 
    wrap: 72
---

```{r}
#| label: setup
#| include: false

knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE, cache.lazy = FALSE,
                      tidy = "styler")
options(tinytex.engine = "xelatex")
```

# Glossary

-   **predicted values**: estimates
-   **fitted values**:
-   **conditional effects**: predictions that are conditioned on certain
    levels (typically the reference level) of factors. For example, the
    trend/effects of one predictor at the first level (or first
    combination) of other categorical predictor(s).
-   **marginal effects**: predictions that are marginalised (= averaged)
    over all levels of the factors. For example, the trend/effects of
    one predictor averaged across all levels (or combinations) of other
    predictors.

### **Predicted Values vs. Fitted Values**

**Predicted Values:**

-   Predicted values are the outputs from a statistical model using new
    or unseen data.

-   They represent what the model estimates the response variable to be,
    given the values of the predictor variables.

-   Often used to make forecasts or predictions about future
    observations.

**Fitted Values:**

-   Fitted values are the outputs from a statistical model using the
    same data that was used to fit (train) the model.

-   They represent the model's estimates of the response variable for
    the observed data.

-   Used to assess how well the model fits the training data by
    comparing these values to the actual observed values.

### **Conditional Effects vs. Marginal Effects**

**Conditional Effects:**

-   Conditional effects refer to the predicted changes in the response
    variable given specific levels or combinations of other predictor
    variables.

-   These effects are "conditioned" on certain values of the other
    predictors, typically the reference level or a specific combination.

-   For example, the effect of a treatment at a specific level of
    another variable (like age or gender).

**Marginal Effects:**

-   Marginal effects refer to the average predicted changes in the
    response variable, averaged over all levels of other predictor
    variables.

-   These effects give a more generalized view by considering the
    average effect of a predictor across the entire dataset.

-   For example, the average effect of a treatment across all age groups
    or both genders.

### Examples for Better Understanding

**Predicted Values:**

\- If you have a model predicting house prices based on features like
size, location, and number of bedrooms, a predicted value is what the
model says a house with specific features will cost.

**Fitted Values:**

\- Using the same model, the fitted values are what the model estimates
the prices to be for the houses in the training dataset. These can be
compared to the actual prices to check the model's accuracy.

**Conditional Effects:**

\- If you're looking at the effect of education level on salary, a
conditional effect might show the predicted salary increase for each
additional year of education, assuming the individual is at the
reference level of experience and gender (e.g., 0 years of experience
and male).

**Marginal Effects:**

\- In the same salary model, a marginal effect would show the average
predicted salary increase for each additional year of education,
averaged across all levels of experience and gender in your dataset.

### **Key Takeaways**

-   **Predicted values** are used for new data.

-   **Fitted values** are used for the training data.

-   **Conditional effects s**how how predictors affect the response
    variable under specific conditions.

-   **Marginal effects s**how how predictors affect the response
    variable on average across all conditions.

# Visualising models

| Package     | Function                   | Type              | Notes             |
|-------------|----------------------------|-------------------|-------------------|
| `sjPlot`    | `plot_model(type = 'eff')` | Marginal means    |                   |
| `effects`   | `allEffects()`             | Marginal means    |                   |
| `ggeffects` | `ggeffects()`              | Marginal means    | calls `effects()` |
| `ggeffects` | `ggpredict()`              | Conditional means | calls `predict()` |
| `ggeffects` | `ggemmeans()`              | Marginal means    | calls `emmeans()` |
|             |                            |                   |                   |

# RÂ²

| Model             | Appropriate $R^2$ | Formula                         | Interpreted as | Function                        |
|-------------------|-------------------|---------------------------------|----------------|---------------------------------|
| Logisitic         | Tjur's R2         | $\dagger$                       |                | `performace::r2_tjur()`         |
| Multinomial Logit | McFadden's R2     | $\ddagger$                      | 1 & 2          | `performace::r2_mcfadden()`     |
| GLM               | Nagelkerke's R2   | $\S$                            | 2              | `performace::r2_nagelkerke()`   |
| GLM               | Likelihood ratio  | Adjusted Nagelkerke - see below |                | `MuMIn::r2.squaredLR()`         |
| Mixed models      | Nakagawa's R2     | Too complex                     |                | `performace::r2_nakagawa()`     |
| Mixed models      |                   |                                 |                | `MuMIn::r.suaredGLMM()`         |
| ZI models         | Zero-inflated R2  | Too complex                     |                | `performace::r2_zeroinflated()` |
| Bayesian models   | Bayes R2          | Too complex                     |                | `performace::r2_bayes()`        |

$\dagger$:
$R^2=\frac{1}{n_{1}}\sum \hat{\pi}(y=1) - \frac{1}{n_{0}}\sum \hat{\pi}(y=0)$

$\ddagger$: $R^2=1-\frac{logL(x)}{logL(0)}$

$\S$: $R^2=\frac{1-(\frac{logL(0)}{logL(x)})^{2/N}}{1-logl(0)^{2/N}}$

where $n_1$ and $n_0$ are the number of 1's and 0's in the response and
$\hat{\pi}$ is the predicted probability. $logL(x)$ and $logL(0)$ are
the log-likelihoods of the fitted and null models respectively and $N$
is the number of observations.

Note, if you run `performance::r2()`, the function will work out what
type of model has been fit and then use the appropriate function from
the above table.
